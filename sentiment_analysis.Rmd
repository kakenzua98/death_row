---
title: "sentiment_analysis"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(stringr)
library(fs)
library(scales)
library(lubridate)
library(dplyr)
library(knitr)
library(tibble)
library(foreign)
library(kableExtra)
library(formattable)
library(readxl)
library(readr)
library(janitor)
library(tibble)
library(purrr)
library(ggplot2)
library(ggrepel)
library(tidytext)

# Here I'm reading in the offender data, cleaning names, and mutating the data so that full name is a combo of first name and last name
# This data is the data from Texas Department of justiceon executions


offender_data <- read_excel("offender_data/offender_2014-18.xlsx") %>% 
  clean_names() %>% 
  mutate(full_name = paste(first_name, last_name, sep = " ")) %>% 
  select(-last_name, -first_name)

write_rds(offender_data, "death_row_app/last_words.rds")

clean_data <- offender_data %>% 
  unnest_tokens(word, last_words)

word_cloud <- clean_data %>% 
  inner_join(get_sentiments("nrc")) %>% 
  select(word) 

# I'm sure there are many better ways to determine the frequency of words, but this is how I did it on the midterm and the only way I know how at the moment
# I restrcited it to just the word variable so it would get frequency of values in that column

word_freq <- data.frame(table(word_cloud$word)) 

write_rds(word_freq, "death_row_app/word_freq.rds")
  

totals <- clean_data %>% 
  count(full_name) %>%
  # Rename the new column
  rename(total_words = n)

# Here I combined word_counts with totals since totals is just name and number of words but I'd like to maintain more info

word_counts <- clean_data %>% 
  left_join(totals, by = "full_name")

# This dataframe is for some of the information that I lost while counting and selecting 
# I'm sure there's a way to go around it but I couldn't figure it out in time

add_later <- offender_data %>% 
  select(-last_words)


# This data is all the legally documented exections across the united states
# This is a different data source than the Texas specific data and has different variables

execution_database <- read_excel("offender_data/all_execution_database.xlsx") %>% 
  clean_names() 
  
# Here I'm mainly just altering the date in the data for easy plotting in the app file

state_executions <- execution_database %>% 
  mutate(date = ymd(date)) %>% 
  mutate(date = floor_date(date, unit = "12 months"))

write_rds(state_executions, "death_row_app/state_executions.rds")

```

Most Common Words
```{r}

# Here I'm getting the top words and I'm using NRC so I can see the  breakdown between multiple sentiments
# I group by sentiment since that will ultimately be how users will interact with the data for this table in the app

top_words <- word_counts %>%
  inner_join(get_sentiments("nrc")) %>%
  count(word, sentiment) %>% 
  # Group by sentiment
  group_by(sentiment) %>%
  ungroup() %>%
  # Make word a factor in order of n
  mutate(word = reorder(word, n))

write_rds(top_words, "death_row_app/top_words.rds")

```

As time passes - can allow break down by race
```{r}

# Here, I'm looking at how sentiment changes as time passes
# I used bing, rather than nrc because I just wanted to look at positive and negative rather than other sentiments like joy, anger, etc.

sentiment_by_time <- clean_data %>%
  mutate(date = floor_date(date, unit = "2 months")) %>%
  group_by(date) %>% 
  mutate(total_words = n()) %>% 
  ungroup() %>%
  inner_join(get_sentiments("bing")) 

write_rds(sentiment_by_time, "death_row_app/sentiment_by_time.rds")

  
```


